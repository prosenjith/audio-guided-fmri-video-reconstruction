# Audio-Guided Cross-Modal Fusion for fMRI-to-Video Reconstruction

This repository contains the official implementation of the paper:

**Audio-Guided Cross-Modal Fusion for fMRI-to-Video Reconstruction**  
Prosenjith Roy Shuvo, Zareen Tasneem  
Primeasia University, Dhaka, Bangladesh

ğŸ“„ *Under review*  
ğŸ“… December 2025

---

## Overview

Reconstructing dynamic video content from fMRI is fundamentally constrained by the **low temporal resolution** of neural measurements (TR â‰ˆ 2s).  
Existing fMRI-to-video approaches rely almost exclusively on neural signals, which limits accurate motion estimation and leads to temporally unstable reconstructions.

This work introduces an **audio-guided cross-modal fusion framework** that uses **synthesized audio as an auxiliary temporal prior** to compensate for missing high-frequency temporal information in fMRI.

> **Important:**  
> The synthesized audio is **not assumed to be neurally encoded**.  
> It is used purely as an **engineered, model-level temporal prior**.

---

## Key Idea

- fMRI provides **coarse spatial and semantic information**
- Synthesized audio provides **dense temporal structure**
- Cross-attention fuses both modalities
- Motion is predicted from the fused representation
- Motion conditions a frozen video diffusion model

This improves:
- Temporal smoothness
- Motion stability
- Object coherence
- Perceptual video quality

---

## Pipeline Overview

```
Stimulus Video
â”‚
â”œâ”€â”€ fMRI â†’ PCA â†’ fMRI Embedding
â”‚
â”œâ”€â”€ Caption â†’ AudioLDM â†’ Synthesized Audio
â”‚ â†“
â”‚ Wav2Vec2
â”‚ â†“
â”‚ Audio Embedding
â”‚
â””â”€â”€ Cross-Attention Fusion (fMRI + Audio)
â†“
Motion Decoder
â†“
Motion-Guided Video Diffusion
â†“
Reconstructed Video
```
---

## Repository Structure

```
audio-guided-fmri-video-reconstruction/
â”‚
â”œâ”€â”€ configs/ # YAML experiment configurations
â”‚ â”œâ”€â”€ fmri_embedding.yaml
â”‚ â”œâ”€â”€ audio_embedding.yaml
â”‚ â”œâ”€â”€ fusion.yaml
â”‚ â”œâ”€â”€ motion_decoder_fmri.yaml
â”‚ â”œâ”€â”€ motion_decoder_fusion.yaml
â”‚ â”œâ”€â”€ video_reconstruction.yaml
â”‚ â”œâ”€â”€ eval_video_reconstruction.yaml
â”‚ â””â”€â”€ eval_video_qualitative.yaml
â”‚
â”œâ”€â”€ scripts/ # Executable experiment scripts
â”‚ â”œâ”€â”€ run_fmri_embeddings.py
â”‚ â”œâ”€â”€ run_audio_embeddings.py
â”‚ â”œâ”€â”€ run_fusion_embeddings.py
â”‚ â”œâ”€â”€ train_motion_decoder_fmri.py
â”‚ â”œâ”€â”€ train_motion_decoder_fusion.py
â”‚ â”œâ”€â”€ generate_videos.py
â”‚ â”œâ”€â”€ evaluate_video_reconstruction.py
â”‚ â”œâ”€â”€ evaluate_video_qualitative.py
â”‚ â””â”€â”€ summarize_qualitative_eval.py
â”‚
â”œâ”€â”€ src/ # Core library code
â”‚ â”œâ”€â”€ fmri/ # fMRI preprocessing & embeddings
â”‚ â”œâ”€â”€ audio/ # Audio synthesis & embeddings
â”‚ â”œâ”€â”€ fusion/ # Cross-attention fusion modules
â”‚ â”œâ”€â”€ motion/ # Motion decoders
â”‚ â”œâ”€â”€ video/ # Video generation & evaluation
â”‚ â”‚ â”œâ”€â”€ generation.py
â”‚ â”‚ â”œâ”€â”€ evaluation.py
â”‚ â”‚ â”œâ”€â”€ metrics.py
â”‚ â”‚ â”œâ”€â”€ plotting.py
â”‚ â”‚ â””â”€â”€ qualitative.py
â”‚ â”œâ”€â”€ pipeline/ # End-to-end orchestration
â”‚ â””â”€â”€ utils/
â”‚
â”œâ”€â”€ notebooks/ # Colab / analysis notebooks
â”‚ â””â”€â”€ 11.2_qualitative_evaluation_of_reconstructed_videos.ipynb
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ logs/
â”‚ â””â”€â”€ results/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
---

## Installation

### Local / Colab Setup

```
git clone https://github.com/prosenjith/audio-guided-fmri-video-reconstruction.git
cd audio-guided-fmri-video-reconstruction
pip install -r requirements.txt
```

### For Google Colab:
```
from google.colab import drive
drive.mount('/content/drive')
```

---
## Data

**Dataset:** Dynamic Natural Vision (DNV)  
**fMRI:** Whole-brain 7T recordings  
**Stimuli:** Naturalistic videos (3â€“5s segments)  
**Audio:** Synthesized per video segment using AudioLDM  

Due to licensing constraints, raw fMRI data and stimulus videos are **not included** in this repository.

---

## Expected Directory Layout (Example)

```text
MyDrive/Research/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fmri/
â”‚   â”œâ”€â”€ stimuli/
â”‚   â”‚   â””â”€â”€ videos/
â”‚   â””â”€â”€ audio/
â”œâ”€â”€ models/
â””â”€â”€ evaluation/
```
---

## Running the Pipeline

1. fMRI Embeddings
`
python scripts/run_fmri_embeddings.py --config configs/fmri_embedding.yaml
`

2. Audio Embeddings
`
python scripts/run_audio_embeddings.py --config configs/audio_embedding.yaml
`

3. Fusion Embeddings
```python scripts/run_fusion_embeddings.py --config configs/fusion.yaml```

4. Train Motion Decoders
```
python scripts/train_motion_decoder_fmri.py
python scripts/train_motion_decoder_fusion.py
```

5. Video Generation
```python scripts/generate_videos.py```

---

## Evaluation

**Quantitative Evaluation**

```python scripts/evaluate_video_reconstruction.py```

Metrics:
- SSIM â†‘
- PSNR
- LPIPS â†“

**Qualitative Evaluation**

The qualitative pipeline follows a timeline-based human evaluation protocol:
- Uniform frame sampling
- Timeline visualization (GT vs fMRI-only vs Fusion)
- Manual annotation
- CSV-based logging
```
python scripts/evaluate_video_qualitative.py
python scripts/summarize_qualitative_eval.py
```

Qualitative criteria:
- Motion alignment
- Temporal smoothness
- Object coherence
- Overall perceptual preference

Results Summary
- SSIM: +2.01%
- LPIPS: +1.93%
- PSNR: âˆ’0.84% (expected perceptual trade-off)
- Human preference: Fusion preferred in 63â€“78% of samples
- Fusion consistently improves temporal stability and motion coherence.

---

## Design Philosophy

- âŒ No claim of auditory neural decoding  
- âœ… Audio used as an engineered temporal prior  
- âœ… Frozen diffusion model (engineering simplicity)  
- âœ… Focus on robustness, interpretability, and reproducibility  

---

## Limitations

- Depends on synthesized audio quality  
- Motion conditioning is indirect  
- Limited subject count  
- Short video segments  

---

## Citation

If you use this work, please cite:

```bibtex
@article{shuvo2025audioguided,
  title   = {Audio-Guided Cross-Modal Fusion for fMRI-to-Video Reconstruction},
  author  = {Shuvo, Prosenjith Roy and Tasneem, Zareen},
  journal = {Under Review},
  year    = {2025}
}
```

## Contact

**Prosenjith Roy Shuvo**  
ğŸ“§ **royprosenjith@gmail.com**

For questions, issues, or collaboration, feel free to open an issue or contact me directly.

---
